{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e935fa2-6f8b-408f-8c96-6664ca458234",
   "metadata": {},
   "source": [
    "## Lecture 16: Mixture Models: EM Algorithm (MIT Lecture Notes)\n",
    "\n",
    "This is a companion notebook to tackle the **project** for Unit4. The detailed notes are in **Expectation Maximization.pptx**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982b7f2-2697-4e48-8037-ff80a0259bc7",
   "metadata": {},
   "source": [
    "**EM Algorithm: GMM (Clustering)**\n",
    "\n",
    "This is a boiler-plate template to get you guys started on how Expectation and Maximization steps can be implimented using numpy arrays.\n",
    "\n",
    "Just to emphasize:\n",
    "\n",
    "**E Step**\n",
    "- For each point $i$ st $i \\in \\{1,2,3..N\\}$\n",
    "    - For each. cluster $j$ st $j \\in \\{1,2,3..K\\}$\n",
    "        - Compute $p(j|i)=\\frac{p_jN(x^i,\\mu_j,\\sigma_jI)}{\\sum_{j}p_jN(x^i,\\mu_j,sigma_jI)}$\n",
    "        \n",
    "**M Step**\n",
    "- Compute $n_j=\\sum^{N}_{i=1}p(j|i)$\n",
    "- From $n_j$ compute $p_j=\\frac{n_j}{N}$\n",
    "- From $p_j$ and $n_j$ compute $\\mu_j = \\frac{1}{n_j}\\sum^{N}_{i=1}p(j|i)x^i$\n",
    "- From $p_j$, $n_j$ and $\\mu_j$ compute $\\sigma_j = \\frac{1}{n_j d}\\sum^{N}_{i=1}p(j|i)||x^i-\\mu_j||^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8426d4a1-f76d-4aa6-8f3e-30299784d67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Python Toy Implimentation EM\n",
    "import numpy as np\n",
    "X = np.loadtxt(\"./data/toy_data.txt\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249d8ce1-c5c5-4c1d-b720-d34bdba77730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.806 0.903] [-1.809  1.69 ]\n"
     ]
    }
   ],
   "source": [
    "### Step 1: Randomly select the value of parameter (mu,sigma,pj)\n",
    "import random\n",
    "random.seed(42)\n",
    "mu_1 = X[random.randint(0,250)]\n",
    "mu_2 = X[random.randint(0,250)]\n",
    "print(mu_1,mu_2)\n",
    "mu = np.array([mu_1,mu_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8e5e08-b7f3-4310-9feb-f3308d3a1e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.806, 0.903])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead90c1c-0e67-4c48-907f-b7f664c9ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=X[1]\n",
    "p_1 = 1/250\n",
    "p_2 = 1/250\n",
    "sigma_1 = 0.45\n",
    "sigma_2 = sigma_1\n",
    "mixture = np.array([p_1,p_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d315b2-41af-424a-9537-787a92afc77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2025, 0.    ],\n",
       "       [0.    , 0.2025]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "s1 = np.identity(2)*sigma_1**2\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceaa8734-5261-45a7-a512-53218f6e354b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.8625252785376755e-52"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.multivariate_normal.pdf(x1,mean=mu_1,cov=s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3009c1-00b8-43f4-8a24-946e85de723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estep\n",
    "k = 2\n",
    "post = np.zeros((X.shape[0],k))\n",
    "ll = 0\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(k):\n",
    "        likelihood = stats.multivariate_normal.pdf(X[i],mean=mu[j],cov=s1)\n",
    "        post[i,j] = likelihood*mixture[j]\n",
    "    total = post[i, :].sum()\n",
    "    post[i, :] = post[i, :] / total\n",
    "    ll += np.log(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e22ae5c-8d02-4ee0-968a-84316c5e0a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.45529942e-34 1.00000000e+00]\n",
      " [4.78320795e-50 1.00000000e+00]\n",
      " [3.15151092e-48 1.00000000e+00]\n",
      " [2.87265827e-45 1.00000000e+00]\n",
      " [7.42177645e-41 1.00000000e+00]\n",
      " [2.68275838e-42 1.00000000e+00]\n",
      " [2.98155824e-36 1.00000000e+00]\n",
      " [4.05552397e-44 1.00000000e+00]\n",
      " [1.14696855e-38 1.00000000e+00]\n",
      " [1.42271413e-43 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(post[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "205e8c73-155a-442c-834e-24e75aced89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6910.840224000402"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "004777e7-11ef-41bb-ad37-8cf2df33fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MStep\n",
    "n, d = X.shape\n",
    "_, K = post.shape\n",
    "\n",
    "n_hat = post.sum(axis=0)\n",
    "p = n_hat / n\n",
    "\n",
    "mu = np.zeros((K, d))\n",
    "var = np.zeros(K)\n",
    "for j in range(K):\n",
    "    # Computing mean\n",
    "    mu[j, :] = (X * post[:, j, None]).sum(axis=0) / n_hat[j]\n",
    "    # Computing variance\n",
    "    sse = ((mu[j] - X)**2).sum(axis=1) @ post[:, j]\n",
    "    var[j] = sse / (d * n_hat[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16aba33c-3b44-49f9-bf95-5c68f722a815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.43571374,  0.15121951],\n",
       "       [-2.32260134,  0.85912116]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca78191a-196a-48d7-91ce-80d439f2dc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.35983655, 2.76291311])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2e75c9-08e0-49b2-8d04-2e7808a34c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43657641, 0.56342359])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdac1795-ae5f-45b4-91f9-4a141f9ff025",
   "metadata": {},
   "source": [
    "**KMeans Using EM**\n",
    "\n",
    "One can also frame k-means as a special case of EM algorithm.\n",
    "\n",
    "|EM: GMM|EM:Kmeans|\n",
    "|--------|---------|\n",
    "|**E Step:** $p(j,i)$ is computed based on a Gaussian Mixture of cluster centers|**E Step:** We simply find out points which are near the means|\n",
    "|**M Step:** $\\mu$,$\\sigma$ and $p_j$ are updated based on $n_j$ obtained from $p(j,i)$ obtained in previous step| **M Step**: Only $\\mu$ is updated based on the cluster assignments done previous step|\n",
    "\n",
    "Below is the code given as part of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e74f4e-8253-42cb-a868-56078d663e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from common import GaussianMixture, plot, init\n",
    "\n",
    "\n",
    "def estep(X: np.ndarray, mixture: GaussianMixture) -> np.ndarray:\n",
    "    \"\"\"E-step: Assigns each datapoint to the gaussian component with the\n",
    "    closest mean\n",
    "\n",
    "    Args:\n",
    "        X: (n, d) array holding the data\n",
    "        mixture: the current gaussian mixture\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: (n, K) array holding the soft counts\n",
    "            for all components for all examples\n",
    "\n",
    "        \"\"\"\n",
    "    n, _ = X.shape\n",
    "    K, _ = mixture.mu.shape\n",
    "    post = np.zeros((n, K))\n",
    "\n",
    "    for i in range(n):\n",
    "        tiled_vector = np.tile(X[i, :], (K, 1))\n",
    "        sse = ((tiled_vector - mixture.mu)**2).sum(axis=1)\n",
    "        j = np.argmin(sse)\n",
    "        post[i, j] = 1 ## You can notice here we are simply hard counting which points belong to which clusters based on distance,(line 25 and 26) \n",
    "\n",
    "    return post\n",
    "\n",
    "\n",
    "def mstep(X: np.ndarray, post: np.ndarray) -> Tuple[GaussianMixture, float]:\n",
    "    \"\"\"M-step: Updates the gaussian mixture. Each cluster\n",
    "    yields a component mean and variance.\n",
    "\n",
    "    Args: X: (n, d) array holding the data\n",
    "        post: (n, K) array holding the soft counts\n",
    "            for all components for all examples\n",
    "\n",
    "    Returns:\n",
    "        GaussianMixture: the new gaussian mixture\n",
    "        float: the distortion cost for the current assignment\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    _, K = post.shape\n",
    "\n",
    "    n_hat = post.sum(axis=0)\n",
    "    p = n_hat / n\n",
    "\n",
    "    cost = 0\n",
    "    mu = np.zeros((K, d))\n",
    "    var = np.zeros(K)\n",
    "\n",
    "    for j in range(K):\n",
    "        mu[j, :] = post[:, j] @ X / n_hat[j] ## This step is essentially finding mean of points in each cluster\n",
    "        sse = ((mu[j] - X)**2).sum(axis=1) @ post[:, j]\n",
    "        cost += sse\n",
    "        var[j] = sse / (d * n_hat[j])\n",
    "\n",
    "    return GaussianMixture(mu, var, p), cost\n",
    "\n",
    "\n",
    "def run(X: np.ndarray, mixture: GaussianMixture,\n",
    "        post: np.ndarray) -> Tuple[GaussianMixture, np.ndarray, float]:\n",
    "    \"\"\"Runs the mixture model\n",
    "\n",
    "    Args:\n",
    "        X: (n, d) array holding the data\n",
    "        post: (n, K) array holding the soft counts\n",
    "            for all components for all examples\n",
    "\n",
    "    Returns:\n",
    "        GaussianMixture: the new gaussian mixture\n",
    "        np.ndarray: (n, K) array holding the soft counts\n",
    "            for all components for all examples\n",
    "        float: distortion cost of the current assignment\n",
    "    \"\"\"\n",
    "\n",
    "    prev_cost = None\n",
    "    cost = None\n",
    "    while (prev_cost is None or prev_cost - cost > 1e-4):\n",
    "        prev_cost = cost\n",
    "        post = estep(X, mixture)\n",
    "        mixture, cost = mstep(X, post)\n",
    "\n",
    "    return mixture, post, cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5ee999-7d04-4c0f-a165-31c7d5a2c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(X):\n",
    "    for K in range(1, 5):\n",
    "        min_cost = None\n",
    "        best_seed = None\n",
    "        for seed in range(0, 5):\n",
    "            mixture, post = init(X, K, seed)\n",
    "            mixture, post, cost = run(X, mixture, post)\n",
    "            if min_cost is None or cost < min_cost:\n",
    "                min_cost = cost\n",
    "                best_seed = seed\n",
    "\n",
    "        mixture, post = init(X, K, best_seed)\n",
    "        mixture, post, cost = run(X, mixture, post)\n",
    "        print(f'cost: {cost} k:{K}, seed:{seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83715e84-7880-4f80-97f7-62be97e4384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt(\"./data/toy_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac693c6f-bb71-4c34-945f-2701be85ce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost: 5462.297452340001 k:1, seed:4\n",
      "cost: 1684.9079502962372 k:2, seed:4\n",
      "cost: 1329.5948671544297 k:3, seed:4\n",
      "cost: 1035.499826539466 k:4, seed:4\n"
     ]
    }
   ],
   "source": [
    "run_kmeans(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d6143-7880-4460-b8b2-105f15253fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
