{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c448b0-83cf-4567-826d-87ff73703769",
   "metadata": {},
   "source": [
    "## Unit 2 Project\n",
    "\n",
    "This notebook contains some additional hints to the project for unit 2. \n",
    "\n",
    "**Softmax Function**\n",
    "\n",
    "Softmax is used in multiclass classification problems where we need to estimate the probabilities of multiple classes using a single model.\n",
    "\n",
    "See the excel sheet **\"Softmax Function\"** for numerical example of softmax.\n",
    "\n",
    "For the project you will need to impliment a softmax function. Below are some hints on how you can do that\n",
    "\n",
    "1. Theta will be a matrix of dimension (k,d), where k is number of classes and d refers to the number of features:\n",
    "\n",
    "$$Theta = \\begin{bmatrix}\n",
    "\\Theta_0\\\\\n",
    "\\Theta_1\\\\\n",
    "\\vdots\\\\\n",
    "\\Theta_n\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "\\theta_{00}&\\theta_{01}&\\dots\\theta_{0d}\\\\\n",
    "\\theta_{10}&\\theta_{11}&\\dots\\theta_{1d}\\\\\n",
    "\\theta_{20}&\\theta_{21}&\\dots\\theta_{2d}\\\\\n",
    "\\vdots\\\\\n",
    "\\theta_{k0}&\\theta_{n1}&\\dots\\theta_{kd}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "2. Data Matrix will be $X$ of dimension (n,d) with each row representing an d dimensional data point.\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "x_{00}& x_{01}&\\dots&x_{0d}\\\\\n",
    "x_{10}& x_{11}&\\dots&x_{1d}\\\\\n",
    "x_{20}& x_{21}&\\dots&x_{2d}\\\\\n",
    "\\vdots\\\\\n",
    "x_{n0}& x_{n1}&\\dots&x_{nd}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "3. To get the softmax we can first compute the following:\n",
    "\n",
    "$$Theta \\times X^T = \\begin{bmatrix}\n",
    "\\theta_{00}&\\theta_{01}&\\dots\\theta_{0d}\\\\\n",
    "\\theta_{10}&\\theta_{11}&\\dots\\theta_{1d}\\\\\n",
    "\\theta_{20}&\\theta_{21}&\\dots\\theta_{2d}\\\\\n",
    "\\vdots\\\\\n",
    "\\theta_{k0}&\\theta_{n1}&\\dots\\theta_{kd}\n",
    "\\end{bmatrix} \\times  \\begin{bmatrix}\n",
    "x_{00}& x_{10}&\\dots&x_{n0}\\\\\n",
    "x_{01}& x_{11}&\\dots&x_{n1}\\\\\n",
    "x_{02}& x_{12}&\\dots&x_{n2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{0d}& x_{1d}&\\dots&x_{nd}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$exp(Theta \\times X^T ) = exp(\\begin{bmatrix}\n",
    "\\theta_{00}&\\theta_{01}&\\dots\\theta_{0d}\\\\\n",
    "\\theta_{10}&\\theta_{11}&\\dots\\theta_{1d}\\\\\n",
    "\\theta_{20}&\\theta_{21}&\\dots\\theta_{2d}\\\\\n",
    "\\vdots\\\\\n",
    "\\theta_{k0}&\\theta_{n1}&\\dots\\theta_{kd}\n",
    "\\end{bmatrix} \\times  \\begin{bmatrix}\n",
    "x_{00}& x_{10}&\\dots&x_{n0}\\\\\n",
    "x_{01}& x_{11}&\\dots&x_{n1}\\\\\n",
    "x_{02}& x_{12}&\\dots&x_{n2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{0d}& x_{1d}&\\dots&x_{nd}\\\\\n",
    "\\end{bmatrix})$$\n",
    "\n",
    "4. Find the column sums and divide by result above to get the softmax\n",
    "\n",
    "\n",
    "**Log Loss**\n",
    "\n",
    "The project also demands that you write the implimentation of log-loss, which is a loss function used to measure how far off a multiclass classifier is. Refer to the sheet **log loss** for an intuitive explanation.\n",
    "\n",
    "\n",
    "To compute the log loss using numpy over a matrix of probabilities obtained by using softmax function described above, observe that the output of softmax will look as given below:\n",
    "\n",
    "$$ P = \\begin{bmatrix}\n",
    "p_{c=0,0}& p_{c=0,1}&\\dots&p_{c=0,n}\\\\\n",
    "p_{c=1,0}& p_{c=1,1}&\\dots&p_{c=1,n}\\\\\n",
    "p_{c=2,0}& p_{c=2,1}&\\dots&p_{c=2,n}\\\\\n",
    "\\vdots\\\\\n",
    "p_{c=k,0}& p_{c=k,1}&\\dots&p_{c=k,n}\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Now for the sake of discussion lets assume that the y vector looks as below\n",
    "\n",
    "$Y = [3,5,0..1]$\n",
    "\n",
    "This means that the probability corresponding to the first label in y is the 4th element in the first column of probability matrix. We can use numpy function \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "np.choose(labels, probabilities)\n",
    "```\n",
    "to choose probabilities corresponding to the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59319a94-97b5-4897-8c59-3044c47df90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb1473b3-a398-4d21-b0dd-5ff0e046e104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [10, 11, 12, 13],\n",
       "       [20, 21, 22, 23],\n",
       "       [30, 31, 32, 33]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices = np.array([[0, 1, 2, 3], [10, 11, 12, 13],\n",
    "[20, 21, 22, 23], [30, 31, 32, 33]])\n",
    "choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b9823b-a9ab-4b00-9721-9de2ee28dd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be155e9-4ca6-4e56-986b-aaca8e5ad2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 31, 12,  3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.choose([2, 3, 1, 0], choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697ae7d-a68d-4fac-943e-5f206f68d8c5",
   "metadata": {},
   "source": [
    "**Gradient Descent For Log Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e68bce1-a37b-496d-89be-ce4ab0dd0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a361bed7-14aa-4ad7-b9a5-c85b449c28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 10\n",
    "num_examples = 10 ## rows in data\n",
    "Y = [0,0,1,1,2,2,3,3,4,5] ## labels in data\n",
    "M = coo_matrix(([1]*num_examples, (Y,range(num_examples))), shape=(num_labels,num_examples)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34f4f29f-98f1-4ff1-82b4-151a6e721daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e192fa-8c94-4a60-bdec-e51b68f21982",
   "metadata": {},
   "source": [
    "The gradient for the loss as given in ![](../gradient_ll.png)\n",
    "\n",
    "The first part of the loss can be computed by the follwing experession:\n",
    "\n",
    "\n",
    "$\\frac{1}{rn}*(M-Probabilities).X$\n",
    "\n",
    "The second is simply the scalar product of lambda and theta matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44414d0a-5b7b-45bf-a5ae-270182f62474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
